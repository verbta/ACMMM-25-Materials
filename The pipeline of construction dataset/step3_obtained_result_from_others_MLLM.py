"""
In step3, we first need to get other MLLM's answer and clue-reasoning pairs with the image and the question generated by step1.
And then we using paraphrase-MiniLM-L12-v2 to measure the silimarity among them.

Let the answer1 is the output by MLLM1 in step1
    the answer2 is the output by MLLM2 in step3
    the answer3 is the output by MLLM3 in step3

    if similarity(answer1, answer2) < 0.7 or similarity(answer1, answer3) < 0.7 or similarity(answer2, answer3) < 0.7:
       remove
"""
import os
import asyncio
import aiohttp
import base64
import json
from pathlib import Path
import cv2
import re
from collections import defaultdict
from sentence_transformers import SentenceTransformer, util


API_KEY = 'XXXXXX'
BASE_URL = "XXXXXX"
headers = {
    "Authorization": f"Bearer {API_KEY}",
    "Content-Type": "application/json",
}

def encode_image(image):
    _, encoded_img = cv2.imencode('.jpg', image)
    return base64.b64encode(encoded_img).decode('utf-8')


def split_and_visualize(image_path):
    img = cv2.imread(image_path)
    if img is None:
        raise FileNotFoundError(f"Image not found at {image_path}")

    h, w = img.shape[:2]


    top_left = img[:h // 2, :w // 2]
    top_right = img[:h // 2, w // 2:]
    bottom_left = img[h // 2:, :w // 2]
    bottom_right = img[h // 2:, w // 2:]


    def upscale(part):
        return cv2.resize(part, (w, h), interpolation=cv2.INTER_LANCZOS4)

    top_left_upscaled = upscale(top_left)
    top_right_upscaled = upscale(top_right)
    bottom_left_upscaled = upscale(bottom_left)
    bottom_right_upscaled = upscale(bottom_right)


    original_encoded = encode_image(img)
    top_left_encoded = encode_image(top_left_upscaled)
    top_right_encoded = encode_image(top_right_upscaled)
    bottom_left_encoded = encode_image(bottom_left_upscaled)
    bottom_right_encoded = encode_image(bottom_right_upscaled)

    return original_encoded, top_left_encoded, top_right_encoded, bottom_left_encoded, bottom_right_encoded


async def analyze_global(session, image_base64, tl, tr, bl, br, question):
    example_dict = {
        "answer": "...",
        "visual clue": [{"clue1": "...", "reasoning": "..."}, {"clue2": "...", "reasoning": "..."}]
    }
    example_json_string = json.dumps(example_dict, ensure_ascii=False, indent=2)
    Question1 = (
    "Analyze the image, first answer the question. Then provide a description of the visual clues supporting the answer and the "
    "reasoning, paying special attention to those unobtrusive details that contain rich information. Avoid discussing image quality, "
    "shooting techniques or angles, and avoid diverging towards art, literature, etc. Note that the visual description should only"
    " involve the objectively existing content in the image. Note that some images have more than two clues, and you should find "
    "all clues that can support the answer (especially those visual information with a small visual proportion). Directly output a "
    "JSON format, and the example output is as follows. Note that no other characters should appear outside the JSON format\n"
    f"```\n{example_json_string}\n```")
    Question2 = question + Question1


    retries = 0
    MAX_RETRIES= 3

    while retries < MAX_RETRIES:
        try:
            async with session.post(
                    url=f"{BASE_URL}chat/completions",
                    json={
                        "model": "XXX",
                        "temperature": 0.5,
                        "response_format":{"type": "json_object"},
                        "messages": [
                            {"role": "user", "content": [{"type": "text", "text": "You are an expert for image analysis"}]},
                            {"role": "user", "content": [
                                {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{image_base64}"}}]},
                            {"role": "user", "content": [
                                {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{tl}"}}]},
                            {"role": "user", "content": [
                                {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{tr}"}}]},
                            {"role": "user", "content": [
                                {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{bl}"}}]},
                            {"role": "user", "content": [
                                {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{br}"}}]},
                            {"role": "user", "content": [{"type": "text", "text": Question2}]},
                        ],
                    },
                    headers=headers,
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    return result['choices'][0]['message']['content']
                else:
                    print(f"Global analysis wrong with code: {response.status}")
                    return None
        except Exception as e:
            retries += 1
            print(f"Global analysis wrong，retry ({retries}/{MAX_RETRIES}): {e}")
            if retries >= MAX_RETRIES:
                print("The number of retry maximum, failed process。")
                return None


async def process_image(session, image_path):
    try:
        ori, tl, tr, bl, br = split_and_visualize(image_path)
        json_path = Path(image_path).with_suffix(".json")
        with open(json_path, 'r', encoding='utf-8') as f:
            meta = json.load(f)

            question = meta.get("question", "")

        if "XXX" in meta: #mode name,
            print("The image has been processed by xxx", image_path)
            return
        else:
            global_description = await analyze_global(session, ori, tl, tr, bl, br, question)
            if global_description is None:
                print(f"Global analysis wrong: {image_path}")
                return

            cleaned_json = global_description.strip('`').strip().replace('json', '', 1).strip().strip('`')
            cleaned_json = cleaned_json.replace("“", '"').replace("”", '"')
            cleaned_json = cleaned_json.replace("，", ',')

            try:
                parsed_data = json.loads(cleaned_json)
            except json.JSONDecodeError as e:

                return

            meta["XXX"] = parsed_data
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(meta, f, indent=4, ensure_ascii=False)
            print(f"The image has been processed successfully: {image_path}")
    except Exception as e:
        print(f"An error occurred while processing the image: {image_path}, error information: {e}")


async def batch_process_images(folder_path, batch_size=50):

    image_files = [f for f in os.listdir(folder_path) if f.endswith(".jpg")]
    anno_files = [f for f in os.listdir(folder_path) if f.endswith(".json")]


    image_files = [os.path.join(folder_path, f) for f in image_files]
    timeout = aiohttp.ClientTimeout(total=300)

    async with aiohttp.ClientSession(timeout=timeout) as session:

        for i in range(0, len(image_files), batch_size):
            batch = image_files[i:i + batch_size]
            tasks = [process_image(session, path) for path in batch]
            await asyncio.gather(*tasks)
            print(f"Processed batch {i // batch_size + 1}/{(len(image_files) - 1) // batch_size + 1}")


# 主函数
if __name__ == "__main__":
    folder_path = "PATH"  # Replace with you target path
    asyncio.run(batch_process_images(folder_path))